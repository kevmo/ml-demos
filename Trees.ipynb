{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b611101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Step 1: Import Libraries and Load Data\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Step 2: Filter the Data\n",
    "# Keep only the records where ocean_proximity is either '<1H OCEAN' or 'INLAND'\n",
    "data = data[data['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\n",
    "\n",
    "# Step 3: Handle Missing Values and Transform Target Variable\n",
    "# Fill missing values with zeros\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Apply the log transform to median_house_value\n",
    "data['median_house_value'] = np.log1p(data['median_house_value'])\n",
    "\n",
    "# Step 4: Train/Validation/Test Split\n",
    "# Do train/validation/test split with 60%/20%/20% distribution\n",
    "df_train_full, df_test = train_test_split(data, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n",
    "\n",
    "# Separate the target variable\n",
    "y_train = df_train['median_house_value'].values\n",
    "y_val = df_val['median_house_value'].values\n",
    "y_test = df_test['median_house_value'].values\n",
    "\n",
    "# Drop the target variable from the dataframes\n",
    "df_train = df_train.drop(columns=['median_house_value'])\n",
    "df_val = df_val.drop(columns=['median_house_value'])\n",
    "df_test = df_test.drop(columns=['median_house_value'])\n",
    "\n",
    "# Step 5: Convert DataFrames to Matrices\n",
    "# Use DictVectorizer(sparse=True) to turn the dataframes into matrices\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "X_test = dv.transform(df_test.to_dict(orient='records'))\n",
    "\n",
    "# Now the dataset is ready for modeling!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a037bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- ocean_proximity=<1H OCEAN <= 0.50\n",
      "|   |--- value: [11.61]\n",
      "|--- ocean_proximity=<1H OCEAN >  0.50\n",
      "|   |--- value: [12.30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "\n",
    "# Assuming you have already prepared your data and it's stored in X_train and y_train\n",
    "# (following the previous steps and code)\n",
    "\n",
    "# Initialize the DecisionTreeRegressor model\n",
    "tree_model = DecisionTreeRegressor(max_depth=1)\n",
    "\n",
    "# Train the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the tree's decision rules\n",
    "tree_rules = export_text(tree_model, feature_names=list(dv.get_feature_names_out()))\n",
    "\n",
    "# Print the decision rules\n",
    "print(tree_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176468e",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9581dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24518772479229903\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee75bf3",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a914df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, RMSE: 0.24518772479229908\n",
      "n_estimators: 20, RMSE: 0.23867351078447516\n",
      "n_estimators: 30, RMSE: 0.23688677870552852\n",
      "n_estimators: 40, RMSE: 0.23526544363339155\n",
      "n_estimators: 50, RMSE: 0.23486891959219142\n",
      "n_estimators: 60, RMSE: 0.23441399445846697\n",
      "n_estimators: 70, RMSE: 0.234331236384555\n",
      "n_estimators: 80, RMSE: 0.23447831103515132\n",
      "n_estimators: 90, RMSE: 0.2343177360969172\n",
      "n_estimators: 100, RMSE: 0.23419468428037377\n",
      "n_estimators: 110, RMSE: 0.23414103115617693\n",
      "n_estimators: 120, RMSE: 0.23396413774464705\n",
      "n_estimators: 130, RMSE: 0.23378469210996636\n",
      "n_estimators: 140, RMSE: 0.23360640922635745\n",
      "n_estimators: 150, RMSE: 0.2334964135185024\n",
      "n_estimators: 160, RMSE: 0.2333384875091416\n",
      "n_estimators: 170, RMSE: 0.23329859841692557\n",
      "n_estimators: 180, RMSE: 0.2334700171311343\n",
      "n_estimators: 190, RMSE: 0.23371183202257467\n",
      "n_estimators: 200, RMSE: 0.23365273265963638\n",
      "Best n_estimators: 170, Best RMSE: 0.23329859841692557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize variables to store the best RMSE and corresponding n_estimators\n",
    "best_rmse = float('inf')\n",
    "best_n = None\n",
    "\n",
    "# Iterate over n_estimators from 10 to 200 with a step of 10\n",
    "for n in range(10, 201, 10):\n",
    "    # Initialize the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    \n",
    "    print(f'n_estimators: {n}, RMSE: {rmse}')\n",
    "    \n",
    "    # Update the best RMSE and n_estimators if the current RMSE is lower\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_n = n\n",
    "#     else:\n",
    "#         # Stop if RMSE is not improving\n",
    "#         break\n",
    "\n",
    "print(f'Best n_estimators: {best_n}, Best RMSE: {best_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3e67c",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b4cbfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10, Mean RMSE: 0.24545499602392812\n",
      "max_depth: 15, Mean RMSE: 0.2359206336413971\n",
      "max_depth: 20, Mean RMSE: 0.23515134491947065\n",
      "max_depth: 25, Mean RMSE: 0.2348258660390293\n",
      "Best max_depth: 25, Best Mean RMSE: 0.2348258660390293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the list of max_depth values\n",
    "max_depths = [10, 15, 20, 25]\n",
    "\n",
    "# Initialize variables to store the best mean RMSE and corresponding max_depth\n",
    "best_mean_rmse = float('inf')\n",
    "best_depth = None\n",
    "\n",
    "# Iterate over different values of max_depth\n",
    "for depth in max_depths:\n",
    "    rmses = []\n",
    "    # Iterate over n_estimators from 10 to 200 with a step of 10\n",
    "    for n in range(10, 201, 10):\n",
    "        # Initialize the Random Forest model\n",
    "        rf_model = RandomForestRegressor(n_estimators=n, max_depth=depth, random_state=1, n_jobs=-1)\n",
    "        \n",
    "        # Train the model on the training data\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the validation data\n",
    "        y_pred = rf_model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    # Calculate mean RMSE for the current max_depth\n",
    "    mean_rmse = np.mean(rmses)\n",
    "    print(f'max_depth: {depth}, Mean RMSE: {mean_rmse}')\n",
    "    \n",
    "    # Update the best mean RMSE and max_depth if the current mean RMSE is lower\n",
    "    if mean_rmse < best_mean_rmse:\n",
    "        best_mean_rmse = mean_rmse\n",
    "        best_depth = depth\n",
    "\n",
    "print(f'Best max_depth: {best_depth}, Best Mean RMSE: {best_mean_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2f825",
   "metadata": {},
   "source": [
    "### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fd5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rooms: 0.02151782701191468\n",
      "median_income: 0.33559170042109715\n",
      "total_bedrooms: 0.015894018592137876\n",
      "longitude: 0.08627637578575545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model\n",
    "rf_model = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance information\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = dv.get_feature_names_out()\n",
    "\n",
    "# Create a dictionary to hold feature names and their importance scores\n",
    "importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Print the importance of the specified features\n",
    "for feature in ['total_rooms', 'median_income', 'total_bedrooms', 'longitude']:\n",
    "    print(f'{feature}: {importance_dict[feature]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb2519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.07362\tval-rmse:8.07348\n",
      "[5]\ttrain-rmse:1.38983\tval-rmse:1.38852\n",
      "[10]\ttrain-rmse:0.33195\tval-rmse:0.34802\n",
      "[15]\ttrain-rmse:0.22197\tval-rmse:0.25614\n",
      "[20]\ttrain-rmse:0.20036\tval-rmse:0.24508\n",
      "[25]\ttrain-rmse:0.18991\tval-rmse:0.24021\n",
      "[30]\ttrain-rmse:0.18204\tval-rmse:0.23833\n",
      "[35]\ttrain-rmse:0.17091\tval-rmse:0.23452\n",
      "[40]\ttrain-rmse:0.16422\tval-rmse:0.23379\n",
      "[45]\ttrain-rmse:0.15756\tval-rmse:0.23302\n",
      "[50]\ttrain-rmse:0.15210\tval-rmse:0.23262\n",
      "[55]\ttrain-rmse:0.14633\tval-rmse:0.23167\n",
      "[60]\ttrain-rmse:0.14218\tval-rmse:0.23160\n",
      "[65]\ttrain-rmse:0.13898\tval-rmse:0.23169\n",
      "[70]\ttrain-rmse:0.13471\tval-rmse:0.23108\n",
      "[75]\ttrain-rmse:0.13072\tval-rmse:0.23036\n",
      "[80]\ttrain-rmse:0.12835\tval-rmse:0.23045\n",
      "[85]\ttrain-rmse:0.12534\tval-rmse:0.23010\n",
      "[90]\ttrain-rmse:0.12174\tval-rmse:0.22957\n",
      "[95]\ttrain-rmse:0.11894\tval-rmse:0.22906\n",
      "[99]\ttrain-rmse:0.11656\tval-rmse:0.22897\n",
      "RMSE for eta=0.3: 0.22897404244864047\n",
      "[0]\ttrain-rmse:10.37456\tval-rmse:10.37545\n",
      "[5]\ttrain-rmse:6.13433\tval-rmse:6.13236\n",
      "[10]\ttrain-rmse:3.63299\tval-rmse:3.62939\n",
      "[15]\ttrain-rmse:2.15901\tval-rmse:2.15616\n",
      "[20]\ttrain-rmse:1.29412\tval-rmse:1.29329\n",
      "[25]\ttrain-rmse:0.78993\tval-rmse:0.79342\n",
      "[30]\ttrain-rmse:0.50217\tval-rmse:0.51149\n",
      "[35]\ttrain-rmse:0.34590\tval-rmse:0.36371\n",
      "[40]\ttrain-rmse:0.26743\tval-rmse:0.29345\n",
      "[45]\ttrain-rmse:0.23014\tval-rmse:0.26315\n",
      "[50]\ttrain-rmse:0.21112\tval-rmse:0.24907\n",
      "[55]\ttrain-rmse:0.20315\tval-rmse:0.24427\n",
      "[60]\ttrain-rmse:0.19724\tval-rmse:0.24107\n",
      "[65]\ttrain-rmse:0.19264\tval-rmse:0.23932\n",
      "[70]\ttrain-rmse:0.18911\tval-rmse:0.23824\n",
      "[75]\ttrain-rmse:0.18503\tval-rmse:0.23731\n",
      "[80]\ttrain-rmse:0.18145\tval-rmse:0.23594\n",
      "[85]\ttrain-rmse:0.17807\tval-rmse:0.23475\n",
      "[90]\ttrain-rmse:0.17418\tval-rmse:0.23307\n",
      "[95]\ttrain-rmse:0.17149\tval-rmse:0.23258\n",
      "[99]\ttrain-rmse:0.17000\tval-rmse:0.23234\n",
      "RMSE for eta=0.1: 0.2323352139407306\n",
      "0.3 leads to the best RMSE\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create DMatrix for train and validation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Create a watchlist\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# Train a model with eta=0.3\n",
    "xgb_params_03 = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_03 = xgb.train(xgb_params_03, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=5)\n",
    "\n",
    "# Predictions and RMSE for eta=0.3\n",
    "y_pred_03 = model_03.predict(dval)\n",
    "rmse_03 = np.sqrt(mean_squared_error(y_val, y_pred_03))\n",
    "print('RMSE for eta=0.3:', rmse_03)\n",
    "\n",
    "# Train a model with eta=0.1\n",
    "xgb_params_01 = xgb_params_03.copy()\n",
    "xgb_params_01['eta'] = 0.1\n",
    "\n",
    "model_01 = xgb.train(xgb_params_01, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=5)\n",
    "\n",
    "# Predictions and RMSE for eta=0.1\n",
    "y_pred_01 = model_01.predict(dval)\n",
    "rmse_01 = np.sqrt(mean_squared_error(y_val, y_pred_01))\n",
    "print('RMSE for eta=0.1:', rmse_01)\n",
    "\n",
    "# Compare RMSE values\n",
    "if rmse_03 < rmse_01:\n",
    "    print('0.3 leads to the best RMSE')\n",
    "elif rmse_01 < rmse_03:\n",
    "    print('0.1 leads to the best RMSE')\n",
    "else:\n",
    "    print('Both give equal value')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f3d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
